{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with missing data\n",
    "\n",
    "Calculate the following three KPIs\n",
    "- % and absolute number of missing data per feature (variable)\n",
    "- % and absolute number of missing data per observation\n",
    "- % and absolute number of missing data overall\n",
    "\n",
    "Overall objective is to achieve 0% missing data, as algorithms/statistics cannot deal with missing values.\n",
    "\n",
    "## < than 10% missing data for each feature and each observation\n",
    "NUMERIC data\n",
    "- analyze if a deletion of the respective features and/or observations would significantly reduce the overall missing data. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. \n",
    "- If not deleted, use a respective imputation method to impute missing values. This should be possible without analyzing possible patterns in the missing data, as with 10% or less missing data, the imputation should not be biased.\n",
    "\n",
    "NON-NUMERIC data\n",
    "- add a dummy variable for missing values\n",
    "\n",
    "## 10% up to 20% missing data for each feature and each observation\n",
    "NUMERIC data\n",
    "- analyze if a deletion of the respective features and/or observations would significantly reduce the overall missing data. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. \n",
    "- If not deleted, analyze if there are patterns in the missing data or is the data missed randomly? Based on this outcome use respective MAR methods (patterns found) or respective MCAR (randomly missed data) to impute missing values. T-Test etc. can be used to find out if the data is missed randomly or not. \n",
    "\n",
    "NON-NUMERIC data\n",
    "- add a dummy variable for missing values\n",
    "\n",
    "## > 20% missing data for each feature and each observation\n",
    "- candidates for deletion. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. If imputation is really needed, go with regression methods for MCAR and model based techniques for MAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data which is stored in the /data folder of the project\n",
    "train_data = pd.read_csv('../data/train.csv', sep=',', header=0)\n",
    "test_data = pd.read_csv('../data/test.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_variable = train_data[\"SalePrice\"]\n",
    "train_features = train_data.drop([\"SalePrice\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first glimps at overall situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overall missing data\n",
    "def overall_missing_data(train_features):\n",
    "    overall_missing = train_features.isnull().sum().sum()\n",
    "    overall_values = train_features.shape[0]*train_features.shape[1]\n",
    "    missing_perc = overall_missing * 100 / overall_values\n",
    "    print(\"Missing values overall: \", overall_missing)\n",
    "    print(\"From total values overall: \", overall_values)\n",
    "    print(\"Resulting in: {0:.2f}% missing data overall\".format(missing_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing data per feature\n",
    "def missing_data_per_feature(train_features):\n",
    "    total_features = train_features.isnull().sum().sort_values(ascending=False)\n",
    "    percent_features = (train_features.isnull().sum()/train_features.isnull().count()*100).sort_values(ascending=False)\n",
    "    missing_data_features = pd.concat([total_features, percent_features], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "    print(missing_data_features.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing data per observation\n",
    "def missing_data_per_observation(train_features):\n",
    "    \n",
    "    observations_with_missing_data = train_features.isnull().replace(to_replace=[False, True], value=['','M'])\n",
    "    \n",
    "    total_observations = train_features.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "    percent_observations = (train_features.isnull().sum(axis=1)/train_features.isnull().count(axis=1)*100).sort_values(ascending=False)\n",
    "    missing_data_observations = pd.concat([total_observations, percent_observations], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "    \n",
    "    return missing_data_observations, observations_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  6965\n",
      "From total values overall:  116800\n",
      "Resulting in: 5.96% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TotalMissing    Percent\n",
      "PoolQC                1453  99.520548\n",
      "MiscFeature           1406  96.301370\n",
      "Alley                 1369  93.767123\n",
      "Fence                 1179  80.753425\n",
      "FireplaceQu            690  47.260274\n",
      "LotFrontage            259  17.739726\n",
      "GarageCond              81   5.547945\n",
      "GarageType              81   5.547945\n",
      "GarageYrBlt             81   5.547945\n",
      "GarageFinish            81   5.547945\n",
      "GarageQual              81   5.547945\n",
      "BsmtExposure            38   2.602740\n",
      "BsmtFinType2            38   2.602740\n",
      "BsmtCond                37   2.534247\n",
      "BsmtQual                37   2.534247\n",
      "BsmtFinType1            37   2.534247\n",
      "MasVnrArea               8   0.547945\n",
      "MasVnrType               8   0.547945\n",
      "Electrical               1   0.068493\n",
      "Utilities                0   0.000000\n",
      "YearRemodAdd             0   0.000000\n",
      "MSSubClass               0   0.000000\n",
      "Foundation               0   0.000000\n",
      "ExterCond                0   0.000000\n",
      "ExterQual                0   0.000000\n",
      "Exterior2nd              0   0.000000\n",
      "Exterior1st              0   0.000000\n",
      "RoofMatl                 0   0.000000\n",
      "RoofStyle                0   0.000000\n",
      "YearBuilt                0   0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data_per_feature(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers, sheet = missing_data_per_observation(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sheet.to_csv(\"../data/missing_values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go and check if there are 'visual' patterns in the missing data sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eliminate features with over 20% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop all features with more than 20% of missing data\n",
    "def delete_features(df, features):\n",
    "    return df.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = delete_features(train_features, ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  868\n",
      "From total values overall:  109500\n",
      "Resulting in: 0.79% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### impute, delete observation, find correlating alternative?\n",
    "MasVnrArea\n",
    "- option 1) delete 8 observations\n",
    "- option 2) find imputing values\n",
    "\n",
    "GarageYrBlt\n",
    "- option 1) possibly correlating with YearBlt, so that GarageYrBlt can be deleted\n",
    "- option 2) find imputing value. will be a random guess\n",
    "- option 2) least preferred: delete 81 observations\n",
    "\n",
    "LotFrontage\n",
    "- option 1) find a correlating feature, so that LotFrontage can be deleted\n",
    "- option 2) impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1201.000000\n",
       "mean       70.049958\n",
       "std        24.284752\n",
       "min        21.000000\n",
       "25%        59.000000\n",
       "50%        69.000000\n",
       "75%        80.000000\n",
       "max       313.000000\n",
       "Name: LotFrontage, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.LotFrontage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a first glimps the missing data seems to be missing randomly. Therefore, it would make sense to impute mean value into missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = delete_features(train_features, ['GarageYrBlt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1452.000000\n",
       "mean      103.685262\n",
       "std       181.066207\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%       166.000000\n",
       "max      1600.000000\n",
       "Name: MasVnrArea, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.MasVnrArea.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 50% of values seem to be on 0. Which is similar to missing in this case?\n",
    "Checked against the MasVnrType. Same picture here. It seems that also MasVnrType is in more than 50% on None. \n",
    "Decision to delete both of these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = delete_features(train_features, ['MasVnrType', 'MasVnrArea']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert non-numeric features into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_interim = delete_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concat test and train data. List all train records first, attach the test data second\n",
    "all_data = pd.concat((train_features, test_interim), axis=0)\n",
    "\n",
    "# convert categorical variables into dummy/indicator variable. \n",
    "# For missing values an additional column will be created - dummy_na\n",
    "# The original feature will be dropped - drop_first \n",
    "all_dummies = pd.get_dummies(all_data, dummy_na=True, drop_first=True)\n",
    "\n",
    "# split test and train sets again\n",
    "train_dummies = all_dummies.iloc[:train_features.shape[0],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get overall statistics of missing again. Only numerical values should be missing, if any is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  348\n",
      "From total values overall:  395660\n",
      "Resulting in: 0.09% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      TotalMissing    Percent\n",
      "LotFrontage                    259  17.739726\n",
      "GarageYrBlt                     81   5.547945\n",
      "MasVnrArea                       8   0.547945\n",
      "Condition1_RRNe                  0   0.000000\n",
      "Condition1_Feedr                 0   0.000000\n",
      "Condition1_Norm                  0   0.000000\n",
      "Condition1_PosA                  0   0.000000\n",
      "Condition1_PosN                  0   0.000000\n",
      "Condition1_RRAe                  0   0.000000\n",
      "Condition1_RRAn                  0   0.000000\n",
      "SaleCondition_nan                0   0.000000\n",
      "Neighborhood_Veenker             0   0.000000\n",
      "Condition1_RRNn                  0   0.000000\n",
      "Condition1_nan                   0   0.000000\n",
      "Condition2_Feedr                 0   0.000000\n",
      "Condition2_Norm                  0   0.000000\n",
      "Condition2_PosA                  0   0.000000\n",
      "Condition2_PosN                  0   0.000000\n",
      "Neighborhood_nan                 0   0.000000\n",
      "Neighborhood_Timber              0   0.000000\n",
      "Condition2_RRAn                  0   0.000000\n",
      "Neighborhood_StoneBr             0   0.000000\n",
      "Neighborhood_Somerst             0   0.000000\n",
      "Neighborhood_SawyerW             0   0.000000\n",
      "Neighborhood_Sawyer              0   0.000000\n",
      "Neighborhood_SWISU               0   0.000000\n",
      "Neighborhood_OldTown             0   0.000000\n",
      "Neighborhood_NridgHt             0   0.000000\n",
      "Neighborhood_NoRidge             0   0.000000\n",
      "Neighborhood_NWAmes              0   0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data_per_feature(train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers, sheet = missing_data_per_observation(train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TotalMissing   Percent\n",
      "1407             2  0.738007\n",
      "287              2  0.738007\n",
      "1030             2  0.738007\n",
      "393              2  0.738007\n",
      "234              2  0.738007\n",
      "1143             2  0.738007\n",
      "529              2  0.738007\n",
      "375              2  0.738007\n",
      "307              2  0.738007\n",
      "826              1  0.369004\n",
      "237              1  0.369004\n",
      "490              1  0.369004\n",
      "1148             1  0.369004\n",
      "269              1  0.369004\n",
      "1153             1  0.369004\n",
      "1154             1  0.369004\n",
      "495              1  0.369004\n",
      "496              1  0.369004\n",
      "1161             1  0.369004\n",
      "465              1  0.369004\n",
      "1097             1  0.369004\n",
      "1164             1  0.369004\n",
      "221              1  0.369004\n",
      "794              1  0.369004\n",
      "218              1  0.369004\n",
      "791              1  0.369004\n",
      "1173             1  0.369004\n",
      "214              1  0.369004\n",
      "789              1  0.369004\n",
      "1177             1  0.369004\n",
      "...            ...       ...\n",
      "916              0  0.000000\n",
      "919              0  0.000000\n",
      "885              0  0.000000\n",
      "920              0  0.000000\n",
      "922              0  0.000000\n",
      "923              0  0.000000\n",
      "924              0  0.000000\n",
      "926              0  0.000000\n",
      "930              0  0.000000\n",
      "931              0  0.000000\n",
      "907              0  0.000000\n",
      "906              0  0.000000\n",
      "905              0  0.000000\n",
      "903              0  0.000000\n",
      "886              0  0.000000\n",
      "887              0  0.000000\n",
      "888              0  0.000000\n",
      "889              0  0.000000\n",
      "890              0  0.000000\n",
      "891              0  0.000000\n",
      "892              0  0.000000\n",
      "894              0  0.000000\n",
      "895              0  0.000000\n",
      "896              0  0.000000\n",
      "897              0  0.000000\n",
      "898              0  0.000000\n",
      "899              0  0.000000\n",
      "901              0  0.000000\n",
      "902              0  0.000000\n",
      "0                0  0.000000\n",
      "\n",
      "[1460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sheet.to_csv(\"../data/missing_values_afterdeletion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies_train = dummies_train.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 288)\n"
     ]
    }
   ],
   "source": [
    "print(dummies_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_variable = np.log(target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies_train['GrLivArea'] = np.log(dummies_train['GrLivArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies_train['HasBsmt'] = pd.Series(len(dummies_train['TotalBsmtSF']), index=dummies_train.index)\n",
    "dummies_train['HasBsmt'] = 0 \n",
    "dummies_train.loc[dummies_train['TotalBsmtSF']>0,'HasBsmt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dummies_train.loc[dummies_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(dummies_train['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(dummies_train, target_variable, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "RandomForestRegressor\n",
      "Root mean squared error: 33444.6661426284\n",
      "Score: 0.8380292506755513\n",
      "==============================\n",
      "DecisionTreeRegressor\n",
      "Root mean squared error: 51957.36056264777\n",
      "Score: 0.6090897817490446\n",
      "==============================\n",
      "LinearRegression\n",
      "Root mean squared error: 58152.52972878381\n",
      "Score: 0.510311296728986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Lasso\n",
      "Root mean squared error: 56954.42649401919\n",
      "Score: 0.5302813246492708\n",
      "==============================\n",
      "ElasticNet\n",
      "Root mean squared error: 50378.19181864712\n",
      "Score: 0.6324909715465268\n",
      "==============================\n",
      "Ridge\n",
      "Root mean squared error: 46849.71131664417\n",
      "Score: 0.6821686741105454\n",
      "==============================\n",
      "SVR\n",
      "Root mean squared error: 85107.83090233327\n",
      "Score: -0.04887058344096018\n",
      "==============================\n",
      "NuSVR\n",
      "Root mean squared error: 83573.53347654763\n",
      "Score: -0.011394040438498898\n",
      "==============================\n",
      "LinearSVR\n",
      "Root mean squared error: 61672.08727027875\n",
      "Score: 0.4492428349735119\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "reg_models = [RandomForestRegressor(n_estimators=300),\n",
    "              DecisionTreeRegressor(),\n",
    "              LinearRegression(),\n",
    "              Lasso(),\n",
    "              ElasticNet(),\n",
    "              Ridge(alpha=2.5),\n",
    "              SVR(),\n",
    "              NuSVR(),\n",
    "              LinearSVR()]\n",
    "\n",
    "log_cols = [\"RegressionModel\", \"RMSE\", \"Score\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for reg in reg_models:\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    name = reg.__class__.__name__\n",
    "\n",
    "    print(\"=\" * 30)\n",
    "    print(name)\n",
    "\n",
    "    train_predictions = reg.predict(X_valid)\n",
    "    rmse = sqrt(mean_squared_error(y_valid, train_predictions))\n",
    "    print(\"Root mean squared error: {}\".format(rmse))\n",
    "    \n",
    "    score = reg.score(X_valid, y_valid)\n",
    "    print(\"Score: {}\".format(score))\n",
    "\n",
    "    log_entry = pd.DataFrame([[name, rmse, score]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train best model\n",
    "rf_reg = RandomForestRegressor(n_estimators=200)\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_ids = dummies_test['Id']\n",
    "dummies_test = dummies_test.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies_test['GrLivArea'] = np.log(dummies_test['GrLivArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies_test['HasBsmt'] = pd.Series(len(dummies_test['TotalBsmtSF']), index=dummies_test.index)\n",
    "dummies_test['HasBsmt'] = 0 \n",
    "dummies_test.loc[dummies_test['TotalBsmtSF']>0,'HasBsmt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dummies_test.loc[dummies_test['HasBsmt']==1,'TotalBsmtSF'] = np.log(dummies_test['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf_reg.predict(dummies_test)\n",
    "\n",
    "# prepare submission as outlined in the submission_sample from Kaggle\n",
    "submission = pd.DataFrame({\"Id\": test_ids,\"SalePrice\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
