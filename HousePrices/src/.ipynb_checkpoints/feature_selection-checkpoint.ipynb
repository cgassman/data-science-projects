{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementary Benchmark and Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough I started to learn about machine learning, I always struggle with the question 'where to begin a new machine learning challenge?'. A lot of good literature is available, but also blog entries etc. can give advice what has to be done in principle. However, the risk remains that as soon as I have to do it by myself, everything becomes somewhat blank. This notebook shows my very first steps I chose to approach Kaggle's House Prices competition in the getting started section.  \n",
    "\n",
    "Three things I did when starting this getting started competition:<br/>\n",
    "1) Load data and have a first glimps at it<br/>\n",
    "2) a very trivial (elementary) benchmark, which will serve as a starting point for my house price prediction model<br/>\n",
    "3) one possible approach for feature selection to improve the trivial benchmark from above<br/>\n",
    "\n",
    "This notebook is inspired by ... and ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and have a first glimps at it\n",
    "set up a new project with the following structure<br>\n",
    "<b>HousePrices</b> <br>\n",
    "<b>|- data</b> *contains the train and test data* <br>\n",
    "<b>|- output</b> *contains generated output files, such as the submission file or an overview.xlsx as explained below etc.* <br>\n",
    "<b>|- src </b> *contains source files e.g. this notebook or .py files etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relevant imports\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    }
   ],
   "source": [
    "# load the train and test data\n",
    "train_data = pd.read_csv('../data/train.csv', sep=',', header=0)\n",
    "test_data = pd.read_csv('../data/test.csv', sep=',', header=0)\n",
    "\n",
    "# have a look at train_data shape. It consists of 1460 observations (rows) and 81 features (columns)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an csv file with all the attributes in the train_data, including their data types. \n",
    "# add additional information I want to capture to each attribute. E.g. my expectation of the attributes relevance etc\n",
    "\n",
    "attributes = list(train_data.columns.values)\n",
    "attr_types = list(train_data.dtypes)\n",
    "\n",
    "overview = pd.DataFrame({\"AttributeNames\": attributes, \"DataType\": attr_types, \"VarType\": \"\", \"Expectation\": \"\",\n",
    "                         \"Conclusion\": \"\", \"Comments\": \"\"})\n",
    "    \n",
    "overview.to_csv(\"../output/overview.csv\", columns=[\"AttributeNames\", \"DataType\", \"VarType\", \"Expectation\", \n",
    "                                                   \"Conclusion\", \"Comments\"], header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I started to read through each attribute. What is meant by it, do I expect that it will be relevant regarding the SalePrice, is it a categorical or a quantitative attribute etc.\n",
    "\n",
    "As an example: From my personal experience and some research in the internet, I came to the conclusion that the area in square meters will be of high relevance, but for example the form of the Hausdach maybe of low relevance and so on. \n",
    "\n",
    "After a first iteration the file still had a lot of gaps in it, but I had a first impression what the attributes are in there and what they mean. \n",
    "\n",
    "In a next step I started to do some descriptive (multivariate) analysis to gain additional insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyse missing data. How much is actually missed in each feature\n",
    "- decide on deleting or completing the feature or on deleting the respective observations causing the missing value.\n",
    "- delete or impute, as decided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TotalMissing   Percent\n",
      "PoolQC                1453  0.995205\n",
      "MiscFeature           1406  0.963014\n",
      "Alley                 1369  0.937671\n",
      "Fence                 1179  0.807534\n",
      "FireplaceQu            690  0.472603\n",
      "LotFrontage            259  0.177397\n",
      "GarageCond              81  0.055479\n",
      "GarageType              81  0.055479\n",
      "GarageYrBlt             81  0.055479\n",
      "GarageFinish            81  0.055479\n",
      "GarageQual              81  0.055479\n",
      "BsmtExposure            38  0.026027\n",
      "BsmtFinType2            38  0.026027\n",
      "BsmtFinType1            37  0.025342\n",
      "BsmtCond                37  0.025342\n",
      "BsmtQual                37  0.025342\n",
      "MasVnrArea               8  0.005479\n",
      "MasVnrType               8  0.005479\n",
      "Electrical               1  0.000685\n",
      "Utilities                0  0.000000\n"
     ]
    }
   ],
   "source": [
    "# analyze missing data\n",
    "\n",
    "total = train_data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "\n",
    "print(missing_data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, I decided to delete all the features (columns) that have more than 5% missing values (e.g. PoolQC, MiscFeature). Additionally, to delete all the observations (rows) that are affected by missing values. I will store this changed dataframe under a new benchmark_data name, as it is radically changing the original dataframe. I decided to go with this mixed column/row delection approach, to soften the radicality. I.e. instead of deleting 8 additional features, I only took out several observations that bring the feature onto this list (e.g. BsmtExposure, BsmtFinType2). \n",
    "\n",
    "Again, this is very radical and maybe not really improving a future model. \n",
    "However, I start with this approach first to be able to submit a high-level benchmark first, before going more into detail.  I will re-think this step later on and follow another strategy then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1412, 70)\n"
     ]
    }
   ],
   "source": [
    "# delete features (columns) with more than 5% missing values\n",
    "benchmark_data = train_data.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
    "                                 'GarageCond', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual'], axis=1)\n",
    "\n",
    "# delete observations (rows) with a missing value in it\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtExposure'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtFinType2'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtFinType1'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtCond'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtQual'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['MasVnrArea'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['MasVnrType'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['Electrical'].isnull()].index)\n",
    "\n",
    "# how is the dataframe shaped now?\n",
    "print(benchmark_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs. (1460, 81) in the original traindata set. Let's proceed with this benchmark_data and come back to this step later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementary benchmark including first submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7009acca48ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train a simple random forest regressor on the X_train part of the benchmark_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# convert categorical features - which are all strings in the current dataframe - into codes\n",
    "benchmark_data = pd.get_dummies(benchmark_data, drop_first=True)\n",
    "\n",
    "# split the benchmark_data into a train and a valid set.\n",
    "target_variable = benchmark_data['SalePrice']\n",
    "features = benchmark_data.drop(['Id', 'SalePrice'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, target_variable, test_size=0.2, random_state=0)\n",
    "\n",
    "# train a simple random forest regressor on the X_train part of the benchmark_data\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# make a prediction for the X_valid part of the benchmark_data, based on the trained model\n",
    "predictions = rf_reg.predict(X_valid)\n",
    "\n",
    "# evaluate performance of your trained model on the X_valid part of the benchmark_data\n",
    "loss = mean_squared_error(y_valid, predictions)\n",
    "print('Loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
