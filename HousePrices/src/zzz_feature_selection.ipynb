{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementary Benchmark and Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough I started to learn about machine learning, I always struggle with the question 'where to begin a new machine learning challenge?'. A lot of good literature is available, but also blog entries etc. can give advice what has to be done in principle. However, the risk remains that as soon as I have to do it by myself, everything becomes somewhat blank. This notebook shows my very first steps I chose to approach Kaggle's House Prices competition in the getting started section.  \n",
    "\n",
    "Three things I did when starting this getting started competition:<br/>\n",
    "1) Load data and have a first glimps at it<br/>\n",
    "2) a very trivial (elementary) benchmark, which will serve as a starting point for my house price prediction model<br/>\n",
    "3) one possible approach for feature selection to improve the trivial benchmark from above<br/>\n",
    "\n",
    "This notebook is inspired by ... and ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and have a first glimps at it\n",
    "set up a new project with the following structure<br>\n",
    "<b>HousePrices</b> <br>\n",
    "<b>|- data</b> *contains the train and test data* <br>\n",
    "<b>|- output</b> *contains generated output files, such as the submission file or an overview.xlsx as explained below etc.* <br>\n",
    "<b>|- src </b> *contains source files e.g. this notebook or .py files etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relevant imports\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    }
   ],
   "source": [
    "# load the train and test data\n",
    "train_data = pd.read_csv('../data/train.csv', sep=',', header=0)\n",
    "test_data = pd.read_csv('../data/test.csv', sep=',', header=0)\n",
    "\n",
    "# have a look at train_data shape. It consists of 1460 observations (rows) and 81 features (columns)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an csv file with all the attributes in the train_data, including their data types. \n",
    "# add additional information I want to capture to each attribute. E.g. my expectation of the attributes relevance etc\n",
    "\n",
    "attributes = list(train_data.columns.values)\n",
    "attr_types = list(train_data.dtypes)\n",
    "\n",
    "overview = pd.DataFrame({\"AttributeNames\": attributes, \"DataType\": attr_types, \"VarType\": \"\", \"Expectation\": \"\",\n",
    "                         \"Conclusion\": \"\", \"Comments\": \"\"})\n",
    "    \n",
    "overview.to_csv(\"../output/overview.csv\", columns=[\"AttributeNames\", \"DataType\", \"VarType\", \"Expectation\", \n",
    "                                                   \"Conclusion\", \"Comments\"], header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I started to read through each attribute. What is meant by it, do I expect that it will be relevant regarding the SalePrice, is it a categorical or a quantitative attribute etc.\n",
    "\n",
    "As an example: From my personal experience and some research in the internet, I came to the conclusion that the area in square meters will be of high relevance, but for example the form of the Hausdach maybe of low relevance and so on. \n",
    "\n",
    "After a first iteration the file still had a lot of gaps in it, but I had a first impression what the attributes are in there and what they mean. \n",
    "\n",
    "In a next step I started to do some descriptive (multivariate) analysis to gain additional insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyse missing data. How much is actually missed in each feature\n",
    "- decide on deleting or completing the feature or on deleting the respective observations causing the missing value.\n",
    "- delete or impute, as decided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TotalMissing   Percent\n",
      "PoolQC                1453  0.995205\n",
      "MiscFeature           1406  0.963014\n",
      "Alley                 1369  0.937671\n",
      "Fence                 1179  0.807534\n",
      "FireplaceQu            690  0.472603\n",
      "LotFrontage            259  0.177397\n",
      "GarageCond              81  0.055479\n",
      "GarageType              81  0.055479\n",
      "GarageYrBlt             81  0.055479\n",
      "GarageFinish            81  0.055479\n",
      "GarageQual              81  0.055479\n",
      "BsmtExposure            38  0.026027\n",
      "BsmtFinType2            38  0.026027\n",
      "BsmtFinType1            37  0.025342\n",
      "BsmtCond                37  0.025342\n",
      "BsmtQual                37  0.025342\n",
      "MasVnrArea               8  0.005479\n",
      "MasVnrType               8  0.005479\n",
      "Electrical               1  0.000685\n",
      "Utilities                0  0.000000\n"
     ]
    }
   ],
   "source": [
    "# analyze missing data\n",
    "\n",
    "total = train_data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "\n",
    "print(missing_data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, I decided to delete all the features (columns) that have more than 5% missing values (e.g. PoolQC, MiscFeature). Additionally, to delete all the observations (rows) that are affected by missing values. I will store this changed dataframe under a new benchmark_data name, as it is radically changing the original dataframe. I decided to go with this mixed column/row delection approach, to soften the radicality. I.e. instead of deleting 8 additional features, I only took out several observations that bring the feature onto this list (e.g. BsmtExposure, BsmtFinType2). \n",
    "\n",
    "Again, this is very radical and maybe not really improving a future model. \n",
    "However, I start with this approach first to be able to submit a high-level benchmark first, before going more into detail.  I will re-think this step later on and follow another strategy then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1412, 70)\n"
     ]
    }
   ],
   "source": [
    "# delete features (columns) with more than 5% missing values\n",
    "benchmark_data = train_data.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
    "                                 'GarageCond', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual'], axis=1)\n",
    "\n",
    "# delete observations (rows) with a missing value in it\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtExposure'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtFinType2'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtFinType1'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtCond'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['BsmtQual'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['MasVnrArea'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['MasVnrType'].isnull()].index)\n",
    "benchmark_data = benchmark_data.drop(benchmark_data.loc[benchmark_data['Electrical'].isnull()].index)\n",
    "\n",
    "# how is the dataframe shaped now?\n",
    "print(benchmark_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs. (1460, 81) in the original traindata set. Let's proceed with this benchmark_data and come back to this step later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementary benchmark including first submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 int64\n",
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotArea            int64\n",
       "Street            object\n",
       "LotShape          object\n",
       "LandContour       object\n",
       "Utilities         object\n",
       "LotConfig         object\n",
       "LandSlope         object\n",
       "Neighborhood      object\n",
       "Condition1        object\n",
       "Condition2        object\n",
       "BldgType          object\n",
       "HouseStyle        object\n",
       "OverallQual        int64\n",
       "OverallCond        int64\n",
       "YearBuilt          int64\n",
       "YearRemodAdd       int64\n",
       "RoofStyle         object\n",
       "RoofMatl          object\n",
       "Exterior1st       object\n",
       "Exterior2nd       object\n",
       "MasVnrType        object\n",
       "MasVnrArea       float64\n",
       "ExterQual         object\n",
       "ExterCond         object\n",
       "Foundation        object\n",
       "BsmtQual          object\n",
       "BsmtCond          object\n",
       "                  ...   \n",
       "Electrical        object\n",
       "1stFlrSF           int64\n",
       "2ndFlrSF           int64\n",
       "LowQualFinSF       int64\n",
       "GrLivArea          int64\n",
       "BsmtFullBath       int64\n",
       "BsmtHalfBath       int64\n",
       "FullBath           int64\n",
       "HalfBath           int64\n",
       "BedroomAbvGr       int64\n",
       "KitchenAbvGr       int64\n",
       "KitchenQual       object\n",
       "TotRmsAbvGrd       int64\n",
       "Functional        object\n",
       "Fireplaces         int64\n",
       "GarageCars         int64\n",
       "GarageArea         int64\n",
       "PavedDrive        object\n",
       "WoodDeckSF         int64\n",
       "OpenPorchSF        int64\n",
       "EnclosedPorch      int64\n",
       "3SsnPorch          int64\n",
       "ScreenPorch        int64\n",
       "PoolArea           int64\n",
       "MiscVal            int64\n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "SalePrice          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "categories = np.union1d(train, test)\n",
    "train.apply(lambda x:x.astype('category', categories=categories), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  841733202.478\n",
      "Score:  0.869051001041\n"
     ]
    }
   ],
   "source": [
    "# convert categorical features - which are all strings in the current dataframe - into codes\n",
    "benchmark_data = pd.get_dummies(benchmark_data, drop_first=True)\n",
    "\n",
    "# split the benchmark_data into a train and a valid set.\n",
    "target_variable = benchmark_data['SalePrice']\n",
    "features = benchmark_data.drop(['Id', 'SalePrice'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, target_variable, test_size=0.2, random_state=0)\n",
    "\n",
    "# train a simple random forest regressor on the X_train part of the benchmark_data\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# make a prediction for the X_valid part of the benchmark_data, based on the trained model\n",
    "y_pred = rf_reg.predict(X_valid)\n",
    "\n",
    "# evaluate performance of your trained model on the X_valid part of the benchmark_data\n",
    "loss = mean_squared_error(y_valid, y_pred)\n",
    "print('Loss: ', loss)\n",
    "\n",
    "score = rf_reg.score(X_valid, y_valid)\n",
    "print('Score: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 211 and input n_features is 195 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a75ee74909b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# apply model on test data and make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# prepare submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    353\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 211 and input n_features is 195 "
     ]
    }
   ],
   "source": [
    "# prepare test data. Apply all relevant steps from above\n",
    "test_ids = test_data.Id\n",
    "test_data = test_data.drop(['Id'], axis=1)\n",
    "\n",
    "test_data = test_data.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n",
    "                                 'GarageCond', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual'], axis=1)\n",
    "\n",
    "test_data = test_data.drop(test_data.loc[test_data['BsmtExposure'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['BsmtFinType2'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['BsmtFinType1'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['BsmtCond'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['BsmtQual'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['MasVnrArea'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['MasVnrType'].isnull()].index)\n",
    "test_data = test_data.drop(test_data.loc[test_data['Electrical'].isnull()].index)\n",
    "\n",
    "test_data = pd.get_dummies(test_data, drop_first=True)\n",
    "test_data = test_data.fillna(test_data.mean())\n",
    "\n",
    "# apply model on test data and make predictions\n",
    "predictions = rf_reg.predict(test_data)\n",
    "\n",
    "# prepare submission\n",
    "submission = pd.DataFrame({\"Id\": test_ids,\"SalePrice\": predictions})\n",
    "print(submission.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 107850.   208430.   181959.   187230.   163800.   206234.9  332282.8\n",
      "  171293.2  123971.   172290.    92540.   180130.   216998.   144200.\n",
      "  259490.4  193008.   204740.   122400.   149535.   190783.5  145410.\n",
      "  146910.   219556.5  132590.   131948.   265648.   175039.9  119878.7\n",
      "  221220.   149525.   212350.    82000.   152640.   151300.   169740.\n",
      "  120650.   137600.   161200.   142553.   210882.8  137740.   185073.2\n",
      "  341213.7  129290.   178739.   137060.   174750.    89300.   246110.\n",
      "  202175.   265550.   130190.   119330.   256301.3  323311.6  192500.\n",
      "  130540.   135445.   148690.   272520.   124870.   184228.4  153386.6\n",
      "  296627.7  119125.   247332.8  144930.    83300.   145000.   105750.\n",
      "  144095.   268730.   167385.   117990.8  157263.4  124890.   192580.\n",
      "  189306.5  176042.2  218430.   142885.   170170.   315405.   153940.\n",
      "  121450.   239190.   132540.9  192157.9  193887.   233000.   191435.\n",
      "   91650.   265200.   147900.   216600.   180700.   151150.   193240.\n",
      "  131145.   166745.4  147300.   177633.2   93840.   102620.   123970.\n",
      "  195947.   119975.   141600.   304561.6  151140.   173684.   144200.\n",
      "  112438.3  253851.5  217190.   150515.   100895.   130980.   168590.\n",
      "  141940.    99940.   298975.   162140.   283285.3  283250.   257121.3\n",
      "  362262.4  152815.   169230.   340600.2  233356.8  161296.   460779.9\n",
      "  139859.3   99450.   158383.4  338393.3  176090.   140295.   197040.6\n",
      "  178685.   144378.4  142720.   231276.4  118210.   162650.   407773.2\n",
      "  119938.3   61650.   217446.3  146430.   169750.   128210.   216300.\n",
      "  197500.   148280.   201290.   217950.   204420.   151000.   300106.1\n",
      "  452298.4  253190.   229228.   175750.   128028.7  147595.   131010.\n",
      "  115335.   366406.   228100.   164890.   141430.   272600.   332881.3\n",
      "  117980.   104700.   112270.   111650.    76480.   379750.9  142245.\n",
      "  244008.   257968.   109625.   386803.8  240830.   149330.   218930.\n",
      "  155400.   151450.   102190.   201285.   132185.   229058.   152180.\n",
      "  187960.   145625.   182235.   112140.   147050.   153895.   121453.4\n",
      "  193555.   371411.7  159750.   128450.   193370.   145900.   244550.\n",
      "  106820.   142575.   226290.   125815.   319332.8  237505.6  139100.\n",
      "  179090.   210299.   172864.   128560.   107530.   141800.   135688.\n",
      "  161474.   154140.   209317.9  179040.   134092.5  171350.   182336.5\n",
      "  192443.5  169500.   134046.   174490.   126185.   278409.1  102590.\n",
      "  188022.   139710.   145170.   347620.5  140980.   333389.3  107605.\n",
      "  529391.2  240300.   111640.    86890.   160370.   188833.4  146890.\n",
      "  128220.   364201.8  107000.   374132.2  173945.2  145325.   124490.\n",
      "  243913.2  406367.5  114038.3  209250.   152883.4  187750.   109800.\n",
      "  294100.    87900.   136630.   175283.5  183870.   288175.   150300.\n",
      "  220479.5  123200.   198998.6  135600.   217870.   131930.   159410.\n",
      "  143400.   187695.   140270. ]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86251890799147835"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete features with zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete (two) features with identical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
