{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with missing data\n",
    "\n",
    "Calculate the following three KPIs\n",
    "- % and absolute number of missing data per feature (variable)\n",
    "- % and absolute number of missing data per observation\n",
    "- % and absolute number of missing data overall\n",
    "\n",
    "Overall objective is to achieve 0% missing data, as algorithms/statistics cannot deal with missing values.\n",
    "\n",
    "## Less than 10% missing data for each feature and each observation\n",
    "NUMERIC data\n",
    "- analyze if a deletion of the respective features and/or observations would significantly reduce the overall missing data. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. \n",
    "- If not deleted, use a respective imputation method to impute missing values. This should be possible without analyzing possible patterns in the missing data, as with 10% or less missing data, the imputation should not be biased.\n",
    "\n",
    "NON-NUMERIC data\n",
    "- add a dummy variable for missing values\n",
    "\n",
    "## 10% up to 20% missing data for each feature and each observation\n",
    "NUMERIC data\n",
    "- analyze if a deletion of the respective features and/or observations would significantly reduce the overall missing data. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. \n",
    "- If not deleted, analyze if there are patterns in the missing data or is the data missed randomly? Based on this outcome use respective MAR methods (patterns found) or respective MCAR (randomly missed data) to impute missing values. T-Test etc. can be used to find out if the data is missed randomly or not. \n",
    "\n",
    "NON-NUMERIC data\n",
    "- add a dummy variable for missing values\n",
    "\n",
    "## More than 20% missing data for each feature and each observation\n",
    "- candidates for deletion. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. If imputation is really needed, go with regression methods for MCAR and model based techniques for MAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant imports and data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data which is stored in the /data folder of the project\n",
    "train_data = pd.read_csv('../data/train.csv', sep=',', header=0)\n",
    "test_data = pd.read_csv('../data/test.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_variable = train_data[\"SalePrice\"]\n",
    "train_features = train_data.drop([\"SalePrice\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first glimps at overall situation of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overall missing data\n",
    "def overall_missing_data(train_features):\n",
    "    overall_missing = train_features.isnull().sum().sum()\n",
    "    overall_values = train_features.shape[0]*train_features.shape[1]\n",
    "    missing_perc = overall_missing * 100 / overall_values\n",
    "    print(\"Missing values overall: \", overall_missing)\n",
    "    print(\"From total values overall: \", overall_values)\n",
    "    print(\"Resulting in: {0:.2f}% missing data overall\".format(missing_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing data per feature\n",
    "def missing_data_per_feature(train_features):\n",
    "    total_features = train_features.isnull().sum().sort_values(ascending=False)\n",
    "    percent_features = (train_features.isnull().sum()/train_features.isnull().count()*100).sort_values(ascending=False)\n",
    "    missing_data_features = pd.concat([total_features, percent_features], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "    print(missing_data_features.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing data per observation\n",
    "def missing_data_per_observation(train_features):\n",
    "    \n",
    "    observations_with_missing_data = train_features.isnull().replace(to_replace=[False, True], value=['','M'])\n",
    "    \n",
    "    total_observations = train_features.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "    percent_observations = (train_features.isnull().sum(axis=1)/train_features.isnull().count(axis=1)*100).sort_values(ascending=False)\n",
    "    missing_data_observations = pd.concat([total_observations, percent_observations], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "    \n",
    "    return missing_data_observations, observations_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  6965\n",
      "From total values overall:  116800\n",
      "Resulting in: 5.96% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TotalMissing    Percent\n",
      "PoolQC                1453  99.520548\n",
      "MiscFeature           1406  96.301370\n",
      "Alley                 1369  93.767123\n",
      "Fence                 1179  80.753425\n",
      "FireplaceQu            690  47.260274\n",
      "LotFrontage            259  17.739726\n",
      "GarageCond              81   5.547945\n",
      "GarageType              81   5.547945\n",
      "GarageYrBlt             81   5.547945\n",
      "GarageFinish            81   5.547945\n",
      "GarageQual              81   5.547945\n",
      "BsmtExposure            38   2.602740\n",
      "BsmtFinType2            38   2.602740\n",
      "BsmtCond                37   2.534247\n",
      "BsmtQual                37   2.534247\n",
      "BsmtFinType1            37   2.534247\n",
      "MasVnrArea               8   0.547945\n",
      "MasVnrType               8   0.547945\n",
      "Electrical               1   0.068493\n",
      "Utilities                0   0.000000\n",
      "YearRemodAdd             0   0.000000\n",
      "MSSubClass               0   0.000000\n",
      "Foundation               0   0.000000\n",
      "ExterCond                0   0.000000\n",
      "ExterQual                0   0.000000\n",
      "Exterior2nd              0   0.000000\n",
      "Exterior1st              0   0.000000\n",
      "RoofMatl                 0   0.000000\n",
      "RoofStyle                0   0.000000\n",
      "YearBuilt                0   0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data_per_feature(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_absolutely, missing_patterns = missing_data_per_observation(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_patterns.to_csv(\"../data/missing_values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go and check if there are 'visual' patterns in the missing data sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eliminate features with more than 20% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = train_features.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  868\n",
      "From total values overall:  109500\n",
      "Resulting in: 0.79% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### analyze features with less than 20% missing data\n",
    "MasVnrArea\n",
    "- option 1) delete 8 observations\n",
    "- option 2) find imputing values\n",
    "- option 3) delete feature \n",
    "\n",
    "GarageYrBlt\n",
    "- option 1) possibly correlating with YearBlt, so that GarageYrBlt can be deleted\n",
    "- option 2) find imputing value. will be a random guess\n",
    "- option 2) least preferred: delete 81 observations\n",
    "\n",
    "LotFrontage\n",
    "- option 1) find a correlating feature, so that LotFrontage can be deleted\n",
    "- option 2) impute missing values"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 92,
=======
   "execution_count": 14,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1201.000000\n",
       "mean       70.049958\n",
       "std        24.284752\n",
       "min        21.000000\n",
       "25%        59.000000\n",
       "50%        69.000000\n",
       "75%        80.000000\n",
       "max       313.000000\n",
       "Name: LotFrontage, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.LotFrontage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a first glimps the missing data seems to be missing randomly. Therefore, it would make sense to impute mean value into missing fields"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 93,
=======
   "execution_count": 15,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features['LotFrontage'] = train_features['LotFrontage'].fillna(train_features['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption that GarageYrBlt is highly correlating to YearBlt. Manual data inspection confirms that picture. But let's compare these two variables. -- comparison of two categorial, ordinal variables. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> origin/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_features.drop(['GarageYrBlt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
=======
   "execution_count": 17,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1452.000000\n",
       "mean      103.685262\n",
       "std       181.066207\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%       166.000000\n",
       "max      1600.000000\n",
       "Name: MasVnrArea, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.MasVnrArea.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 50% of values seem to be on 0. Which is similar to missing in this case?\n",
    "Checked against the MasVnrType. Same picture here. It seems that also MasVnrType is in more than 50% on None. \n",
    "Decision to delete both of these variables"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 97,
=======
   "execution_count": 18,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = train_features.drop(['MasVnrType', 'MasVnrArea'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 98,
=======
   "execution_count": 19,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  512\n",
      "From total values overall:  105120\n",
      "Resulting in: 0.49% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_features)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 99,
=======
   "execution_count": 20,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TotalMissing   Percent\n",
      "GarageType               81  5.547945\n",
      "GarageFinish             81  5.547945\n",
      "GarageCond               81  5.547945\n",
      "GarageQual               81  5.547945\n",
      "BsmtExposure             38  2.602740\n",
      "BsmtFinType2             38  2.602740\n",
      "BsmtFinType1             37  2.534247\n",
      "BsmtCond                 37  2.534247\n",
      "BsmtQual                 37  2.534247\n",
      "Electrical                1  0.068493\n",
      "SaleCondition             0  0.000000\n",
      "RoofMatl                  0  0.000000\n",
      "YearRemodAdd              0  0.000000\n",
      "RoofStyle                 0  0.000000\n",
      "Exterior2nd               0  0.000000\n",
      "Exterior1st               0  0.000000\n",
      "OverallCond               0  0.000000\n",
      "ExterQual                 0  0.000000\n",
      "ExterCond                 0  0.000000\n",
      "Foundation                0  0.000000\n",
      "YearBuilt                 0  0.000000\n",
      "BldgType                  0  0.000000\n",
      "OverallQual               0  0.000000\n",
      "HouseStyle                0  0.000000\n",
      "Condition2                0  0.000000\n",
      "Condition1                0  0.000000\n",
      "Neighborhood              0  0.000000\n",
      "LandSlope                 0  0.000000\n",
      "LotConfig                 0  0.000000\n",
      "Utilities                 0  0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data_per_feature(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only categorial data is missing values. Will replace them with a respective dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert non-numeric features into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_interim = delete_features(test_data, ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu','MasVnrType', 'MasVnrArea', 'GarageYrBlt' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concat test and train data. List all train records first, attach the test data second\n",
    "all_data = pd.concat((train_features, test_interim), axis=0)\n",
    "\n",
    "# convert categorical variables into dummy/indicator variable. \n",
    "# For missing values an additional column will be created - dummy_na\n",
    "# The original feature will be dropped - drop_first \n",
    "all_dummies = pd.get_dummies(all_data, dummy_na=True, drop_first=True)\n",
    "\n",
    "# split test and train sets again\n",
    "train_dummies = all_dummies.iloc[:train_features.shape[0],:]\n",
    "test_dummies = all_dummies.iloc[train_features.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get overall statistics of missing again. Only numerical values should be missing, if any is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  0\n",
      "From total values overall:  386900\n",
      "Resulting in: 0.00% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze numeric values\n",
    "- Normality\n",
    "- Linearity\n",
    "- Homoscedasticity\n",
    "- Independence of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dummies = train_dummies.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_dummies, target_variable, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "RandomForestRegressor\n",
      "Root mean squared error: 33346.553824652205\n",
      "Score: 0.8389781623150461\n",
      "==============================\n",
      "DecisionTreeRegressor\n",
      "Root mean squared error: 50740.33876128134\n",
      "Score: 0.6271882547362768\n",
      "==============================\n",
      "LinearRegression\n",
      "Root mean squared error: 54780.619892225324\n",
      "Score: 0.5654530099236712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Lasso\n",
      "Root mean squared error: 53479.3132706555\n",
      "Score: 0.5858530140665199\n",
      "==============================\n",
      "ElasticNet\n",
      "Root mean squared error: 50689.86456913378\n",
      "Score: 0.6279295983216646\n",
      "==============================\n",
      "Ridge\n",
      "Root mean squared error: 45995.96988338715\n",
      "Score: 0.6936467985054583\n",
      "==============================\n",
      "SVR\n",
      "Root mean squared error: 85107.82593096742\n",
      "Score: -0.04887046090654246\n",
      "==============================\n",
      "NuSVR\n",
      "Root mean squared error: 83573.52824369336\n",
      "Score: -0.011393913784108811\n",
      "==============================\n",
      "LinearSVR\n",
      "Root mean squared error: 57033.07231770331\n",
      "Score: 0.5289832019300592\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "reg_models = [RandomForestRegressor(n_estimators=300),\n",
    "              DecisionTreeRegressor(),\n",
    "              LinearRegression(),\n",
    "              Lasso(),\n",
    "              ElasticNet(),\n",
    "              Ridge(alpha=2.5),\n",
    "              SVR(),\n",
    "              NuSVR(),\n",
    "              LinearSVR()]\n",
    "\n",
    "log_cols = [\"RegressionModel\", \"RMSE\", \"Score\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for reg in reg_models:\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    name = reg.__class__.__name__\n",
    "\n",
    "    print(\"=\" * 30)\n",
    "    print(name)\n",
    "\n",
    "    train_predictions = reg.predict(X_valid)\n",
    "    rmse = sqrt(mean_squared_error(y_valid, train_predictions))\n",
    "    print(\"Root mean squared error: {}\".format(rmse))\n",
    "    \n",
    "    score = reg.score(X_valid, y_valid)\n",
    "    print(\"Score: {}\".format(score))\n",
    "\n",
    "    log_entry = pd.DataFrame([[name, rmse, score]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train best model for prediction of test data\n",
    "rf_reg = RandomForestRegressor(n_estimators=200)\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_ids = test_dummies['Id']\n",
    "test_dummies = test_dummies.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf_reg.predict(dummies_test)\n",
    "\n",
    "# prepare submission as outlined in the submission_sample from Kaggle\n",
    "submission = pd.DataFrame({\"Id\": test_ids,\"SalePrice\": predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
