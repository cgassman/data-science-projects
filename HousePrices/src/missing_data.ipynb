{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Determine type of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignorable missing data where no remedies are needed: Some data seems to be missing given through the techniques used. As certain features seem to be very specific characteristics, such as for example PoolQC (describing pool quality, which makes only sense if there is a pool), there might be ignorable missing data.\n",
    "\n",
    "Not_Ignorable missing data, extent and impact have to be assessed, remedies might be needed, if missing data occurs in a random pattern: \n",
    "- known. as the dataset has already been pre-cleaned by Kaggle not expected.  \n",
    "- unknown. Some other data seems to be missing, although a value would be expected. E.g. LotFrontage etc. these missing values cannot be ignored. It has to be analyzed whether a value can be imputed.\n",
    "\n",
    "As a conclusion there might be ignorable as well as not_ignorable (unknown) missing data in the dataset. The extent and impact of missing data have to be determined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant imports and data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data which is stored in the /data folder of the project\n",
    "train_data = pd.read_csv('../data/train.csv', sep=',', header=0)\n",
    "test_data = pd.read_csv('../data/test.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: determine extent of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the following three KPIs\n",
    "- % and absolute number of missing data per feature (variable)\n",
    "- % and absolute number of missing data per observation\n",
    "- % and absolute number of missing data overall\n",
    "\n",
    "Overall objective is to achieve 0% missing data, as algorithms/statistics cannot deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overall missing data\n",
    "def overall_missing_data(df):\n",
    "    overall_missing = df.isnull().sum().sum()\n",
    "    overall_values = df.shape[0]*df.shape[1]\n",
    "    missing_perc = overall_missing * 100 / overall_values\n",
    "    print(\"Missing values overall: \", overall_missing)\n",
    "    print(\"From total values overall: \", overall_values)\n",
    "    print(\"Resulting in: {0:.2f}% missing data overall\".format(missing_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# missing data per feature\n",
    "def missing_data_per_feature(df):\n",
    "    total_features = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent_features = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)\n",
    "    missing_data_features = pd.concat([total_features, percent_features], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "    print(missing_data_features.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# missing data per observation\n",
    "def missing_data_per_observation(df):\n",
    "    \n",
    "    observations_with_missing_data = df.isnull().replace(to_replace=[False, True], value=['','M'])\n",
    "    \n",
    "    total_observations = df.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "    percent_observations = (df.isnull().sum(axis=1)/df.isnull().count(axis=1)*100).sort_values(ascending=False)\n",
    "    missing_data_observations = pd.concat([total_observations, percent_observations], axis=1, keys=['TotalMissing', 'Percent'])\n",
    "    \n",
    "    return missing_data_observations, observations_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  6965\n",
      "From total values overall:  118260\n",
      "Resulting in: 5.89% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TotalMissing    Percent\n",
      "PoolQC                1453  99.520548\n",
      "MiscFeature           1406  96.301370\n",
      "Alley                 1369  93.767123\n",
      "Fence                 1179  80.753425\n",
      "FireplaceQu            690  47.260274\n",
      "LotFrontage            259  17.739726\n",
      "GarageCond              81   5.547945\n",
      "GarageType              81   5.547945\n",
      "GarageYrBlt             81   5.547945\n",
      "GarageFinish            81   5.547945\n",
      "GarageQual              81   5.547945\n",
      "BsmtExposure            38   2.602740\n",
      "BsmtFinType2            38   2.602740\n",
      "BsmtFinType1            37   2.534247\n",
      "BsmtCond                37   2.534247\n",
      "BsmtQual                37   2.534247\n",
      "MasVnrArea               8   0.547945\n",
      "MasVnrType               8   0.547945\n",
      "Electrical               1   0.068493\n",
      "Utilities                0   0.000000\n",
      "YearRemodAdd             0   0.000000\n",
      "MSSubClass               0   0.000000\n",
      "Foundation               0   0.000000\n",
      "ExterCond                0   0.000000\n",
      "ExterQual                0   0.000000\n",
      "Exterior2nd              0   0.000000\n",
      "Exterior1st              0   0.000000\n",
      "RoofMatl                 0   0.000000\n",
      "RoofStyle                0   0.000000\n",
      "YearBuilt                0   0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data_per_feature(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the individual features, there seem to be many ignorable missing data, such as for instance pool quality, alley, fireplace quality etc. in all these cases NA represents the information that the respective building cannot have a pool quality or a fireplace quality etc, because the building has no pool or fireplace\n",
    "\n",
    "Nevertheless, there are also features with missing values which are not_ignorable and the reason why the values are missing are unkonwn. These are for instance the features LotFrontage or Electrical, as well as MasVnrArea and MasVnrType. \n",
    "\n",
    "Let's also have a view on:\n",
    "- missing data per observation, which shows that every observation has at least one missing value\n",
    "- graphical view on missing values or patterns of missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_data_per_observation, missing_patterns = missing_data_per_observation(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TotalMissing    Percent\n",
      "1011            15  18.518519\n",
      "533             15  18.518519\n",
      "1218            15  18.518519\n",
      "39              15  18.518519\n",
      "705             14  17.283951\n",
      "1179            14  17.283951\n",
      "520             14  17.283951\n",
      "375             11  13.580247\n",
      "1035            11  13.580247\n",
      "1143            11  13.580247\n",
      "1030            11  13.580247\n",
      "287             11  13.580247\n",
      "1321            11  13.580247\n",
      "342             11  13.580247\n",
      "613             10  12.345679\n",
      "108             10  12.345679\n",
      "125             10  12.345679\n",
      "210             10  12.345679\n",
      "1219            10  12.345679\n",
      "1407            10  12.345679\n",
      "614             10  12.345679\n",
      "1412            10  12.345679\n",
      "710             10  12.345679\n",
      "102             10  12.345679\n",
      "1283            10  12.345679\n",
      "1000            10  12.345679\n",
      "960             10  12.345679\n",
      "1123            10  12.345679\n",
      "535             10  12.345679\n",
      "1234            10  12.345679\n",
      "...            ...        ...\n",
      "858              3   3.703704\n",
      "115              3   3.703704\n",
      "228              3   3.703704\n",
      "823              3   3.703704\n",
      "836              3   3.703704\n",
      "1171             3   3.703704\n",
      "1040             3   3.703704\n",
      "130              3   3.703704\n",
      "626              3   3.703704\n",
      "390              3   3.703704\n",
      "387              3   3.703704\n",
      "1399             3   3.703704\n",
      "890              2   2.469136\n",
      "1457             2   2.469136\n",
      "766              2   2.469136\n",
      "51               2   2.469136\n",
      "197              2   2.469136\n",
      "1076             2   2.469136\n",
      "1263             2   2.469136\n",
      "733              2   2.469136\n",
      "1182             2   2.469136\n",
      "1083             2   2.469136\n",
      "1170             2   2.469136\n",
      "1387             2   2.469136\n",
      "810              2   2.469136\n",
      "21               2   2.469136\n",
      "439              2   2.469136\n",
      "1210             2   2.469136\n",
      "1386             1   1.234568\n",
      "1328             1   1.234568\n",
      "\n",
      "[1460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(missing_data_per_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_patterns.to_csv(\"../data/missing_values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: diagnose randomness of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "either via empirical tests\n",
    "graphical view on possible patterns - see picture above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Remediation of missing data\n",
    "\n",
    "### Less than 10% missing data for each feature and each observation\n",
    "NUMERIC data\n",
    "- analyze if a deletion of the respective features and/or observations would significantly reduce the overall missing data. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. \n",
    "- If not deleted, use a respective imputation method to impute missing values. This should be possible without analyzing possible patterns in the missing data, as with 10% or less missing data, the imputation should not be biased.\n",
    "\n",
    "NON-NUMERIC data\n",
    "- add a dummy variable for missing values\n",
    "\n",
    "### 10% up to 20% missing data for each feature and each observation\n",
    "NUMERIC data\n",
    "- analyze if a deletion of the respective features and/or observations would significantly reduce the overall missing data. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. \n",
    "- If not deleted, analyze if there are patterns in the missing data or is the data missed randomly? Based on this outcome use respective MAR methods (patterns found) or respective MCAR (randomly missed data) to impute missing values. T-Test etc. can be used to find out if the data is missed randomly or not. \n",
    "\n",
    "NON-NUMERIC data\n",
    "- add a dummy variable for missing values\n",
    "\n",
    "###  More than 20% missing data for each feature and each observation\n",
    "- candidates for deletion. Check if a collinear feature could take over for the one with missing values. Verify if sample size remains big enough. If imputation is really needed, go with regression methods for MCAR and model based techniques for MAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eliminate features with more than 20% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  868\n",
      "From total values overall:  110960\n",
      "Resulting in: 0.78% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### analyze features with less than 20% missing data\n",
    "MasVnrArea\n",
    "- option 1) delete 8 observations\n",
    "- option 2) find imputing values\n",
    "- option 3) delete feature \n",
    "\n",
    "GarageYrBlt\n",
    "- option 1) possibly correlating with YearBlt, so that GarageYrBlt can be deleted\n",
    "- option 2) find imputing value. will be a random guess\n",
    "- option 2) least preferred: delete 81 observations\n",
    "\n",
    "LotFrontage\n",
    "- option 1) find a correlating feature, so that LotFrontage can be deleted\n",
    "- option 2) impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1201.000000\n",
       "mean       70.049958\n",
       "std        24.284752\n",
       "min        21.000000\n",
       "25%        59.000000\n",
       "50%        69.000000\n",
       "75%        80.000000\n",
       "max       313.000000\n",
       "Name: LotFrontage, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.LotFrontage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a first glimps the missing data seems to be missing randomly. Therefore, it would make sense to impute mean value into missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['LotFrontage'] = train_data['LotFrontage'].fillna(train_data['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption that GarageYrBlt is highly correlating to YearBlt. Manual data inspection confirms that picture. But let's compare these two variables. -- comparison of two categorial, ordinal variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['GarageYrBlt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1452.000000\n",
       "mean      103.685262\n",
       "std       181.066207\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%       166.000000\n",
       "max      1600.000000\n",
       "Name: MasVnrArea, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.MasVnrArea.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 50% of values seem to be on 0. Which is similar to missing in this case?\n",
    "Checked against the MasVnrType. Same picture here. It seems that also MasVnrType is in more than 50% on None. \n",
    "Decision to delete both of these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['MasVnrType', 'MasVnrArea'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  512\n",
      "From total values overall:  106580\n",
      "Resulting in: 0.48% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TotalMissing   Percent\n",
      "GarageCond              81  5.547945\n",
      "GarageType              81  5.547945\n",
      "GarageFinish            81  5.547945\n",
      "GarageQual              81  5.547945\n",
      "BsmtFinType2            38  2.602740\n",
      "BsmtExposure            38  2.602740\n",
      "BsmtFinType1            37  2.534247\n",
      "BsmtCond                37  2.534247\n",
      "BsmtQual                37  2.534247\n",
      "Electrical               1  0.068493\n",
      "YearRemodAdd             0  0.000000\n",
      "RoofStyle                0  0.000000\n",
      "RoofMatl                 0  0.000000\n",
      "ExterQual                0  0.000000\n",
      "Exterior1st              0  0.000000\n",
      "Exterior2nd              0  0.000000\n",
      "OverallCond              0  0.000000\n",
      "ExterCond                0  0.000000\n",
      "Foundation               0  0.000000\n",
      "BsmtFinSF1               0  0.000000\n",
      "YearBuilt                0  0.000000\n",
      "SalePrice                0  0.000000\n",
      "OverallQual              0  0.000000\n",
      "LandContour              0  0.000000\n",
      "MSSubClass               0  0.000000\n",
      "MSZoning                 0  0.000000\n",
      "LotFrontage              0  0.000000\n",
      "LotArea                  0  0.000000\n",
      "Street                   0  0.000000\n",
      "LotShape                 0  0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_data_per_feature(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(train_data.loc[train_data['Electrical'].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert non-numeric features into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_interim = test_data.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu','MasVnrType', 'MasVnrArea', 'GarageYrBlt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop SalePrice and add it after get_dummies\n",
    "target_variable = train_data['SalePrice']\n",
    "train_interim = train_data.drop('SalePrice', axis=1)\n",
    "\n",
    "# concat test and train data. List all train records first, attach the test data second\n",
    "all_data = pd.concat((train_interim, test_interim), axis=0)\n",
    "\n",
    "# convert categorical variables into dummy/indicator variable. \n",
    "# For missing values an additional column will be created - dummy_na\n",
    "# The original feature will be dropped - drop_first \n",
    "all_dummies = pd.get_dummies(all_data, dummy_na=True, drop_first=True)\n",
    "\n",
    "# split test and train sets again\n",
    "train_dummies = all_dummies.iloc[:train_interim.shape[0],:]\n",
    "test_dummies = all_dummies.iloc[train_interim.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get overall statistics of missing again. Only numerical values should be missing, if any is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values overall:  0\n",
      "From total values overall:  386635\n",
      "Resulting in: 0.00% missing data overall\n"
     ]
    }
   ],
   "source": [
    "overall_missing_data(train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add SalePrice again\n",
    "train_dummies = train_dummies.assign(SalePrice=target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleType_nan</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SaleCondition_nan</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "\n",
       "   YearRemodAdd  BsmtFinSF1  BsmtFinSF2    ...      SaleType_Oth  SaleType_WD  \\\n",
       "0          2003       706.0         0.0    ...                 0            1   \n",
       "1          1976       978.0         0.0    ...                 0            1   \n",
       "2          2002       486.0         0.0    ...                 0            1   \n",
       "\n",
       "   SaleType_nan  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0             0                      0                     0   \n",
       "1             0                      0                     0   \n",
       "2             0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \\\n",
       "0                     0                     1                      0   \n",
       "1                     0                     1                      0   \n",
       "2                     0                     1                      0   \n",
       "\n",
       "   SaleCondition_nan  SalePrice  \n",
       "0                  0     208500  \n",
       "1                  0     181500  \n",
       "2                  0     223500  \n",
       "\n",
       "[3 rows x 266 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dummies.to_csv(\"../data/train_filled_up.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dummies.to_csv(\"../data/test_filled_up.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
